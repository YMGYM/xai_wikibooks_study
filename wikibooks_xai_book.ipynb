{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "wikibooks_xai_book.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNnOWdFDJ4IAR6k282yz8/4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YMGYM/xai_wikibooks_study/blob/main/wikibooks_xai_book.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Z8RnKxmgEe4"
      },
      "source": [
        "# 개요\n",
        "\n",
        "이 파일은 \n",
        "[<<XAI 설명 가능한 인공지능, 인공지능을 해부하다>>](https://github.com/wikibook/xai)\n",
        "에 대한 코드 실습 및 제가 공부한 내용을 작성하는 노트입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MB2b4bCvkPd"
      },
      "source": [
        "# 1. 이야기를 열며"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "diJnx4RrxnvD"
      },
      "source": [
        "\n",
        "## 1-2 XAI\n",
        "- XAI는 1975년 '설명 가능한 의사 결정 체계' 라는 용어로 처음 등장했다. => 조건부 확률 근삿값을 사용해서 의사 결정 체계 모델링\n",
        "- 16년 뒤, '전문가 시스템' 에서 발전\n",
        "- 2014년에 XAI라는 용어가 등장 (NPC의 행동 이유를 설명하는 아키텍처 제시)\n",
        "- 당시 XAI는 컴퓨팅 파워의 한계로 제한된 범위에서만 사용됨\n",
        "- 오늘날 XAI는 인공지능 모델이 특정 결론을 내리기까지 어떤 근거로 의사 결정을 내렸는지를 알 수 있게 설명 가능성을 추가하는 기법이다.\n",
        "- XAI를 통해 시스템 결과 신뢰, 다음 의사결정에도 사용할 수 있다.\n",
        "\n",
        "#### 한계점\n",
        "- 인공지능의 정확도가 낮은 경우 신뢰하기 어렵다.\n",
        "- 다양한 알고리즘이 서로 상충하는 결과를 내기도 한다.\n",
        "- 이 상황에서 의사 결정을 선택하는 것은 이를 잘 이해하고 있는 데이터 과학자의 숙련도 문제\n",
        "\n",
        "\n",
        "### XAI의 과정\n",
        "1. 기존 머신러닝 모델에 설명 가능한 기능 추가\n",
        "2. 머신러닝 모델에 HCI기능 추가\n",
        "3. XAI를 통한 현재 상황의 개선"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqCpEamqxohC"
      },
      "source": [
        "## 1-3 XAI를 잘하기 위한 조건\n",
        "\n",
        "1. 기존 머신러닝 이론을 충분히 이해하기\n",
        "2. 설명 모델을 어떻게 접목할지 생각하기 (설명 가능성을 높이며 성능도 함께 높이는 방법)\n",
        "3. Explainable Model, Interpretable Models, Model Induction(귀납적 모델)이 XAI의 세 가지 기법이다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qn4cQBpiycZq"
      },
      "source": [
        "## 1-4 xgboost를 사용한 XAI와 딥러닝 XAI\n",
        "\n",
        "- 일반적으로 전통적인 머신러닝 모델에 적용하는 XAI기법은 딥러닝 기법에도 적용 가능\n",
        "- 그러나 딥러닝은 신경망을 이해하고 분해해야 하기 때문에 사용에 제약이 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gmo1mIUV0N7J"
      },
      "source": [
        "# 2. 실습환경 구축\n",
        "\n",
        "`Colab` 환경에서 다 구축되어 있으므로 생략합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HlOigQb0WpN"
      },
      "source": [
        "# 3. XAI 개발 준비"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrt16Rm00heL"
      },
      "source": [
        "## 3-1 머신러닝 이해\n",
        "\n",
        "- 머신러닝 : 학습방식을 먼저 입력하고 기계가 스스로 로직을 만들어가게 제작하는 과정\n",
        "- 머신러닝은 연산 과정이 많거나, 절차가 깊어질수록 학습 과정이 복잡해진다.\n",
        "- 이 과정을 인간이 직접 이해할 수 없을 때 이 모델을 '블랙박스' 라고 부른다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCK5jwQ31G_I"
      },
      "source": [
        "## 3-2 블랙박스 들여다보기\n",
        "\n",
        "- XAI는 머신러닝 모델의 블랙박스 성향을 인간이 이해할 수 있는 수준까지 분해하는 기술\n",
        "- 인공지능의 해석 가능성을 늘리는 행위\n",
        "- '피처 중요도'는 모델이 의사 결정을 수행하는 과정에서 어떤 피처들이 가장 크게 기여했는지를 측정\n",
        "- 피처 중요도는 피처를 탐지하고 특정 피처를 제외하거나 다른 유용한 피처늘 찾을 수 있는 근거가 된다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3sXWMj7n3AFq"
      },
      "source": [
        "## 3-3 시각화와 XAI의 차이 이해하기\n",
        "\n",
        "- XAI의 핵심은 '해석 가능성'이다.\n",
        "- 모델이 왜 특정 결정을 했는지, 해당 모델을 신뢰해야 하는지에 관한 근거를 찾고, 어떤 결과가 예상되는지 판단하는 과정이다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPnGXO153VZt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}